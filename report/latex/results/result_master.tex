In this section we will go over the results of the various experiments we have concocted. The results will be evaluated in two separate ways. For each experiment there are two models, the "final" model that was saved after all training was finished, and the "minloss" model which was saved during training when the model achieved the lowest loss. With the last experiment being the exception, all results shown are from the "final" models.\\

\noindent
The first evaluation will be on a structural classification dataset, which will be a qualitative analysis in which we perform t-distributed stochastic neighbor embedding (TSNE) dimensionality reduction on the data, and see whether it is able to cleanly separate the different types of protein structures. TSNE is preferred here over something like principal component analysis (PCA) due to this non-linearity of the reduction. This evaluation will be performed on the structural classification dataset. While using a classification method like k-nearest neighbors (KNN) might seem intuitive to quantitatively evaluate this, the non-linearity means that neither distance nor density is preserved between data points. We will also look at the next token prediction accuracy for the LSTM, but because we want to quantify how well it represents the proteins, this is not necessarily a good way to do that. It will mostly be used for comparison to see if there are any interesting insights.\\

\noindent
The second evaluation will be on the stability dataset. This evaluation will be quantitative, using Spearman's rank correlation coefficent. This coefficient measures the degree to which the relationship between two inputs can be described using a monotonic function. This means that having a high spearman correlation is equivalent to having a highly descriptive representation. It does not necessarily mean that the linear regression model we have trained provides good results in and of itself, since the coefficient does not describe a 1:1 correlation. This can be seen in figure ~\ref{fig:spearman}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.4\linewidth]{latex/imgs/spearman_fig.png}
  \caption{Graph showing that high spearman correlation does not necessarily mean a good score. Image source:\cite{spearman}}\label{fig:spearman}
\end{figure}

\subsection{LSTM experiments}

\subsubsection{Layers vs no layers}
\input{latex/results/layers}

\subsubsection{Dropout vs no dropout}
\input{latex/results/dropout}

\subsubsection{Feature size}
\input{latex/results/feature_size}

\subsubsection{Learning Rate}
\input{latex/results/lr}

\subsubsection{Minimum loss model vs last model} % Finished
%\input{latex/results/minloss_or_last}

\subsubsection{CNN}
