When taking convolutional layers, and rectified linear unit layers and pooling layers stacking them, so the output of the first, becomes the input of the next operation in the stack. When these operations get stacked like this, one or more fully connected layers are introduced. These fully connected layers are the same as the hidden layers in a feed forward neural network. In a CNN you can have non-convolutional layers, though, one is required for it to be a CNN. A CNN can have multiple of these layer. Normally the last hidden layer before the output-layer is a convolutional layer, since the output of this convolutional layer can help make a better estimation for a correct output.