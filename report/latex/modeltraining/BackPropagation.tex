When a model is run on some input, it predicts some output $\hat{y}$, which the model wants to evaluate against the desired value $y$. This evaluation happens, with some error function. This error functions outputs some loss-value which is dependent on how much $\hat{y}$ deviates from $y$. The greater the deviation is, the greater the loss will become.
Based on the size of the loss, the models know, with how great magnitude it has to adjust its parameters (weights and biases). The goal is to adjust the parameters, so the predicted output $\hat{y}$, gets as close to the desired output $y$.\\

\noindent
This is done with backpropagation. Trying every single combination of weights, in the pursuit of finding the best fitting weights for a specific problem, is a very comprehensive task, even for a computer. The idea is to find the minimum value of which the loss function can take. Calculating the gradient is a very effective way of finding this minimum. Finding this minimum can be achieved with various gradient descent algorithms. the gradient describes the momentum of the function at a specific point in the graph. Assuming we have a function $f$, the following gradient of this function is $f'$. If $f'$ takes some input x, and $f'(x)$ yields a negative result, it means that the graph currently has a negative momentum at this current point. Thus, to get closer to a minimum, we have to increase the value of x. \\

\noindent
But a gradient descent algorithm is an algorithm that finds the minimum given it has a gradient available, it is not the algorithm for finding the gradient. Backpropagation is the method of computing the magnitude each weights gradient has on the final error. The way this is done is by propagating backward through the layers, computing the gradient at each weight. \\

\noindent

