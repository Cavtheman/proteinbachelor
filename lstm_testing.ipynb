{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils import data\n",
    "#from data_generator import data_generator\n",
    "from data_generator import Dataset\n",
    "from lstm import LSTM_model\n",
    "from lstm import LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcdefghijklmnopqrstuvwxyz', 'bcdefghijklmnopqrstuvwxyza', 'cdefghijklmnopqrstuvwxyzab', 'defghijklmnopqrstuvwxyzabc', 'efghijklmnopqrstuvwxyzabcd', 'fghijklmnopqrstuvwxyzabcde', 'ghijklmnopqrstuvwxyzabcdef', 'hijklmnopqrstuvwxyzabcdefg', 'ijklmnopqrstuvwxyzabcdefgh', 'jklmnopqrstuvwxyzabcdefghi', 'klmnopqrstuvwxyzabcdefghij', 'lmnopqrstuvwxyzabcdefghijk', 'mnopqrstuvwxyzabcdefghijkl', 'nopqrstuvwxyzabcdefghijklm', 'opqrstuvwxyzabcdefghijklmn', 'pqrstuvwxyzabcdefghijklmno', 'qrstuvwxyzabcdefghijklmnop', 'rstuvwxyzabcdefghijklmnopq', 'stuvwxyzabcdefghijklmnopqr', 'tuvwxyzabcdefghijklmnopqrs', 'uvwxyzabcdefghijklmnopqrst', 'vwxyzabcdefghijklmnopqrstu', 'wxyzabcdefghijklmnopqrstuv', 'xyzabcdefghijklmnopqrstuvw', 'yzabcdefghijklmnopqrstuvwx', 'zabcdefghijklmnopqrstuvwxy', 'abcdefghijklmnopqrstuvwxyz', 'bcdefghijklmnopqrstuvwxyza', 'cdefghijklmnopqrstuvwxyzab', 'defghijklmnopqrstuvwxyzabc', 'efghijklmnopqrstuvwxyzabcd', 'fghijklmnopqrstuvwxyzabcde']\n"
     ]
    }
   ],
   "source": [
    "def gen_alphabet(mod_val):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    index = mod_val % 26\n",
    "    return alphabet[index:] + alphabet[:index]\n",
    "\n",
    "test = [gen_alphabet(i) for i in range(32)]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: False\n",
      "Input:\t torch.Size([64, 8, 27])\n",
      "Labels:\t torch.Size([8, 64])\n",
      "Valid:\t tensor([26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Output:\t torch.Size([50, 8, 27])\n",
      "Hidden:\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class alpha_set(data.Dataset):\n",
    "    def __gen_acid_dict__(self, acids):\n",
    "        acid_dict = {}\n",
    "        for i, elem in enumerate(acids):\n",
    "            temp = torch.zeros(len(acids))\n",
    "            temp[i] = 1\n",
    "            acid_dict[elem] = temp\n",
    "        return acid_dict\n",
    "    \n",
    "    def __init__(self, acids, length, num_seqs):\n",
    "        self.max_seq_len = length\n",
    "        self.acids = acids\n",
    "        self.acid_dict = self.__gen_acid_dict__(acids)\n",
    "        self.data = [gen_alphabet(i) for i in range(num_seqs)]\n",
    "\n",
    "    def __prepare_seq__(self, seq):\n",
    "        valid_elems = min(len(seq), self.max_seq_len)\n",
    "        seq = str(seq).ljust(self.max_seq_len+1, '-')\n",
    "        temp_seq = [self.acid_dict[x] for x in seq]\n",
    "        tensor_seq = torch.stack(temp_seq[:-1]).float()\n",
    "        #valid_elems = torch.Tensor([elem != '-' for elem in seq[:-1]])\n",
    "\n",
    "        # Labels consisting of the raw tensor\n",
    "        # labels_seq = torch.stack(temp_seq[1:]).long()\n",
    "\n",
    "        # Label consisting of last element\n",
    "        # labels_seq = temp_seq[-1].long()\n",
    "\n",
    "        # Labels consisting of the index of correct class\n",
    "        labels_seq = torch.argmax(torch.stack(temp_seq[1:]), dim=1).long()\n",
    "\n",
    "        #print(labels_seq.size())\n",
    "        #print(tensor_seq.size())\n",
    "        #labels_seq = torch.transpose(labels_seq, 0, 1)\n",
    "        #tensor_seq = torch.transpose(tensor_seq, 0, 1)\n",
    "        #print(\"Seq shape:\", tensor_seq[1:].size())\n",
    "        return tensor_seq, labels_seq, valid_elems\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__prepare_seq__(self.data[index])\n",
    "    \n",
    "\n",
    "# Use Cuda if available\n",
    "use_cuda = torch.cuda.is_available() and False\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "processor = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "max_seq_len = 50\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz-\"\n",
    "alpha_dataset = alpha_set(alphabet, 64, 2000)\n",
    "alpha_generator = data.DataLoader(alpha_dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"sum\").to(processor)\n",
    "lstm = LSTM_model(len(alphabet), 100, 1, max_seq_len, 0).to(processor)\n",
    "optimiser = optim.SGD(lstm.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "\n",
    "for i, (seq, label, valid) in enumerate(alpha_generator):\n",
    "    seq = seq.to(processor)\n",
    "    label = label.to(processor)\n",
    "    valid = valid.to(processor)\n",
    "\n",
    "    seq = seq.transpose(0,1)\n",
    "    #label = label.transpose(0,1)\n",
    "\n",
    "    #label = label.squeeze(0)\n",
    "    if i == 0:\n",
    "        print(\"Input:\\t\", seq.size())\n",
    "        print(\"Labels:\\t\", label.size())\n",
    "        print(\"Valid:\\t\", valid)\n",
    "\n",
    "    \n",
    "    lstm.zero_grad()\n",
    "\n",
    "    seq = rnn.pack_padded_sequence(seq, valid, enforce_sorted=False)\n",
    "    #label = rnn.pack_padded_sequence(label, valid, enforce_sorted=False, batch_first=True)\n",
    "    \n",
    "    out, hidden = lstm(seq)\n",
    "    #out = out.squeeze(1)\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\"Output:\\t\", out.size())\n",
    "        print(\"Hidden:\\t\")#, hidden.size())\n",
    "    #out = out.transpose(1, 2)\n",
    "    \n",
    "    loss = 0\n",
    "    for j in range(out.size()[1]):\n",
    "        narrowed_out = torch.narrow(torch.narrow(out, 1, j, 1).squeeze(1), 0, 0, valid[j])\n",
    "        #print(narrowed_out.size())\n",
    "        #print(torch.argmax(narrowed_out, dim=1))\n",
    "        #print(label[j].size())\n",
    "        narrowed_label = torch.narrow(label[j], 0, 0, valid[j])\n",
    "        \n",
    "        loss += loss_function(narrowed_out, narrowed_label)\n",
    "\n",
    "    #loss /= out.size()[1]\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "Test Accuracy: 98.000%\n",
      "Sequence 0\n",
      "tensor([22, 23, 24, 25,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
      "        14, 15, 16, 17, 18, 19, 20, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 1\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 2\n",
      "tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        20, 21, 22, 23, 24, 25, 26,  1, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 3\n",
      "tensor([14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,  0,  1,  2,  3,  4,  5,\n",
      "         6,  7,  8,  9, 10, 11, 26, 13, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 4\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 5\n",
      "tensor([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,  0,  1,  2,  3,\n",
      "         4,  5,  6,  7,  8,  9, 10, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 6\n",
      "tensor([19, 20, 21, 22, 23, 24, 25,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
      "        11, 12, 13, 14, 15, 16, 17, 18, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n",
      "Sequence 7\n",
      "tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
      "        24, 25,  0,  1,  2,  3,  4,  5, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (seq, label, valid) in enumerate(alpha_generator):\n",
    "        lstm.eval()\n",
    "        seq = seq.to(processor)\n",
    "        label = label.to(processor)\n",
    "        valid = valid.to(processor)\n",
    "        \n",
    "        seq = seq.transpose(0,1)\n",
    "        #label = label.transpose(0,1)\n",
    "\n",
    "        seq = rnn.pack_padded_sequence(seq, valid, enforce_sorted=False)\n",
    "        \n",
    "        out, hidden = lstm(seq)\n",
    "\n",
    "        out = out.transpose(0,1)\n",
    "\n",
    "        correct = 0\n",
    "        for j in range(batch_size):\n",
    "            truths = [1 if pred == truth else 0 for pred, truth in zip(torch.argmax(out[j], dim=1), label[j])]\n",
    "            print(len(truths))\n",
    "            correct += sum(truths)\n",
    "\n",
    "        \n",
    "\n",
    "        #if i > 4:\n",
    "        break\n",
    "accuracy = correct/(batch_size * max_seq_len * (i+1))\n",
    "print(\"Test Accuracy: {0:.3f}%\".format(accuracy*100))\n",
    "\n",
    "def print_preds(preds):\n",
    "    for i, seq in enumerate(preds):\n",
    "        print(\"Sequence {}\".format(i))\n",
    "        indexes = torch.argmax(seq, dim=1)\n",
    "        print(indexes)\n",
    "        #print(\"\".join(ret_val))\n",
    "        \n",
    "print_preds(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "lstm_testing.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
