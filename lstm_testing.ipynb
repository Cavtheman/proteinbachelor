{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils import data\n",
    "#from data_generator import data_generator\n",
    "from data_generator import Dataset\n",
    "from lstm import LSTM_model\n",
    "from lstm import LSTMCell\n",
    "from alpha_set import alpha_set\n",
    "from print_seq import print_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcdefghijklmnopqrstuvwxyz', 'bcdefghijklmnopqrstuvwxyza', 'cdefghijklmnopqrstuvwxyzab', 'defghijklmnopqrstuvwxyzabc', 'efghijklmnopqrstuvwxyzabcd', 'fghijklmnopqrstuvwxyzabcde', 'ghijklmnopqrstuvwxyzabcdef', 'hijklmnopqrstuvwxyzabcdefg', 'ijklmnopqrstuvwxyzabcdefgh', 'jklmnopqrstuvwxyzabcdefghi', 'klmnopqrstuvwxyzabcdefghij', 'lmnopqrstuvwxyzabcdefghijk', 'mnopqrstuvwxyzabcdefghijkl', 'nopqrstuvwxyzabcdefghijklm', 'opqrstuvwxyzabcdefghijklmn', 'pqrstuvwxyzabcdefghijklmno', 'qrstuvwxyzabcdefghijklmnop', 'rstuvwxyzabcdefghijklmnopq', 'stuvwxyzabcdefghijklmnopqr', 'tuvwxyzabcdefghijklmnopqrs', 'uvwxyzabcdefghijklmnopqrst', 'vwxyzabcdefghijklmnopqrstu', 'wxyzabcdefghijklmnopqrstuv', 'xyzabcdefghijklmnopqrstuvw', 'yzabcdefghijklmnopqrstuvwx', 'zabcdefghijklmnopqrstuvwxy', 'abcdefghijklmnopqrstuvwxyz', 'bcdefghijklmnopqrstuvwxyza', 'cdefghijklmnopqrstuvwxyzab', 'defghijklmnopqrstuvwxyzabc', 'efghijklmnopqrstuvwxyzabcd', 'fghijklmnopqrstuvwxyzabcde']\n"
     ]
    }
   ],
   "source": [
    "def gen_alphabet(mod_val):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    index = mod_val % 26\n",
    "    return alphabet[index:] + alphabet[:index]\n",
    "\n",
    "test = [gen_alphabet(i) for i in range(32)]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t torch.Size([2000, 32, 27])\n",
      "Labels:\t torch.Size([32, 2000])\n",
      "Valid:\t tensor([26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
      "        26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26],\n",
      "       device='cuda:0')\n",
      "Output:\t torch.Size([832, 27])\n",
      "Hidden:\t torch.Size([832, 400])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.07563018798828\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "min_loss = float(\"inf\")\n",
    "# Use Cuda if available\n",
    "use_cuda = torch.cuda.is_available() and True\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "processor = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "max_seq_len = 2000\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz-\"\n",
    "alpha_dataset = alpha_set(alphabet, max_seq_len, 3200)\n",
    "alpha_generator = data.DataLoader(alpha_dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"sum\").to(processor)\n",
    "lstm = LSTM_model(len(alphabet), 400, 1, max_seq_len, batch_size, processor).to(processor)\n",
    "optimiser = optim.SGD(lstm.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "\n",
    "for i, (seq, label, valid) in enumerate(alpha_generator):\n",
    "    seq = seq.to(processor)\n",
    "    label = label.to(processor)\n",
    "    valid = valid.to(processor)\n",
    "    lstm.train()\n",
    "    seq = seq.transpose(0,1)\n",
    "    #label = label.transpose(0,1)\n",
    "\n",
    "    #label = label.squeeze(0)\n",
    "    if i == 0:\n",
    "        print(\"Input:\\t\", seq.size())\n",
    "        print(\"Labels:\\t\", label.size())\n",
    "        print(\"Valid:\\t\", valid)\n",
    "\n",
    "    \n",
    "    lstm.zero_grad()\n",
    "\n",
    "    seq = rnn.pack_padded_sequence(seq, valid, enforce_sorted=False)\n",
    "    label = rnn.pack_padded_sequence(label, valid, enforce_sorted=False, batch_first=True)\n",
    "    \n",
    "    out, hidden = lstm(seq)\n",
    "    #out = out.squeeze(1)\n",
    "\n",
    "    out = rnn.pack_padded_sequence(out, valid, enforce_sorted=False)\n",
    "    if i == 0:\n",
    "        print(\"Output:\\t\", out.data.size())\n",
    "        print(\"Hidden:\\t\", hidden.data.size())\n",
    "    #out = out.transpose(1, 2)\n",
    "    \n",
    "    loss = loss_function(out.data, label.data)\n",
    "    if loss.item() < min_loss:\n",
    "        min_loss = loss.item()\n",
    "    '''\n",
    "    for j in range(out.size()[1]):\n",
    "        narrowed_out = torch.narrow(torch.narrow(out, 1, j, 1).squeeze(1), 0, 0, valid[j])\n",
    "        #print(narrowed_out.size())\n",
    "        #print(torch.argmax(narrowed_out, dim=1))\n",
    "        #print(label[j].size())\n",
    "        narrowed_label = torch.narrow(label[j], 0, 0, valid[j])\n",
    "        \n",
    "        loss += loss_function(narrowed_out, narrowed_label)\n",
    "    '''\n",
    "    #loss /= out.size()[1]\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "print(min_loss)\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.913%\n",
      "torch.Size([32, 2000, 27])\n",
      "torch.Size([32, 2000, 27])\n",
      "torch.Size([32])\n",
      "Sequence 0\n",
      "klmnopqrstuvwxyzabcdefghij\n",
      "Sequence 0\n",
      "jklmnopqrstuvwxyzabcdefghi\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for i, (seq, label, valid) in enumerate(alpha_generator):\n",
    "        lstm.eval()\n",
    "        test = seq\n",
    "        seq = seq.to(processor)\n",
    "        label = label.to(processor)\n",
    "        valid = valid.to(processor)\n",
    "        \n",
    "        seq = seq.transpose(0,1)\n",
    "        #label = label.transpose(0,1)\n",
    "\n",
    "        seq = rnn.pack_padded_sequence(seq, valid, enforce_sorted=False)\n",
    "        \n",
    "        out, hidden = lstm(seq)\n",
    "\n",
    "        out = out.transpose(0,1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            preds = torch.argmax(out[j], dim=1)[:valid[j]]\n",
    "            actual = label[j][:valid[j]]\n",
    "            truths = [1 if pred == truth else 0 for pred, truth in zip(preds, actual)]\n",
    "            correct += sum(truths)\n",
    "        accuracy = correct/(torch.sum(valid).item())\n",
    "        break\n",
    "    \n",
    "print(\"Test Accuracy: {0:.3f}%\".format(accuracy*100))\n",
    "\n",
    "print(out.size())\n",
    "print(test.size())\n",
    "print(valid.size())\n",
    "print_seq(out[0].view(1,max_seq_len,27), valid, alphabet)\n",
    "print_seq(test[0].view(1,max_seq_len,27), valid, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "lstm_testing.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
