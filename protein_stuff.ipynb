{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "pUVIpevFD2hz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from Bio import SeqIO\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Our code\n",
    "from data_generator import Dataset\n",
    "from lstm import LSTM_model\n",
    "from lstm import LSTMCell\n",
    "from alpha_set import alpha_set\n",
    "from print_seq import print_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#acids = \"abcdefghijklmnopqrstuvwxyz-\"\n",
    "acids = \"ACDEFGHIKLMNOPQRSTUVWY-\"\n",
    "large_file = \"uniref50.fasta\"\n",
    "small_file = \"100k_rows.fasta\"\n",
    "test_file = \"test.fasta\"\n",
    "\n",
    "#max_seq_len = 50\n",
    "#max_seq_len = 2000\n",
    "max_seq_len = 500\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# Good sizes: 64/512 on laptop\n",
    "# 32/1500 on desktop\n",
    "batch_size = 64\n",
    "hidden_dim = 512\n",
    "\n",
    "embed_size = 30\n",
    "hidden_layers = 1\n",
    "\n",
    "# Use Cuda if available\n",
    "use_cuda = torch.cuda.is_available() and True\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "processor = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# Initialising data generator\n",
    "dataset = Dataset(small_file, max_seq_len, output_type=\"embed\", acids=acids)\n",
    "#dataset = alpha_set(acids, max_seq_len, 3200)\n",
    "base_generator = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "# Initialising for training\n",
    "model = LSTM_model(len(acids), embed_size, hidden_dim, hidden_layers, max_seq_len, batch_size, processor, dropout=0).to(processor)\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"mean\").to(processor)\n",
    "#optimiser = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Best lr so far is 2e-2\n",
    "optimiser = optim.Adam(model.parameters(), lr=8e-4)#, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialising some variables for use in training\n",
    "batches = 500 #float(\"inf\")\n",
    "time_diff = 0\n",
    "no_improv = 0\n",
    "min_loss = float(\"inf\")\n",
    "epochs = 30\n",
    "print_stuff = False\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (batch, labels, valid_elems) in enumerate(base_generator):\n",
    "\n",
    "        # Keeping track of stuff\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        est_time_left = str(time_diff*(min(batches, dataset.__len__()/batch_size) - i) + (time_diff*min(batches, dataset.__len__()/batch_size)) * (epochs - (epoch+1))).split(\".\")[0]\n",
    "        #est_time_left = str(time_diff*(min(batches, dataset.__len__()) - i)+time_diff*(epochs-(epoch+1))*min(batches, dataset.__len__()/batch_size)).split(\".\")[0]\n",
    "        sys.stdout.write(\"\\rEpoch: {0}. Batch: {1}. Min loss: {2:.5f}. Estimated time left: {3}. Best: {4} batches ago.\".format(epoch+1, i+1, min_loss, est_time_left, no_improv))\n",
    "\n",
    "        # Putting data on gpu\n",
    "        batch = batch.to(processor)\n",
    "        labels = labels.to(processor)\n",
    "        valid_elems = valid_elems.to(processor)\n",
    "\n",
    "        # Transposing from (batch x seq x feature_size) to (seq x batch x feature_size)\n",
    "        batch = batch.transpose(0, 1)\n",
    "\n",
    "        # Resetting gradients\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "    \n",
    "        if i == 0 and print_stuff:\n",
    "            print(\"\\nInput:\\t\", batch.size())\n",
    "            print(\"Labels:\\t\", labels.size())\n",
    "            print(\"Valid:\\t\", valid_elems)\n",
    "\n",
    "        labels = rnn.pack_padded_sequence(labels, valid_elems, enforce_sorted=False, batch_first=True)\n",
    "\n",
    "        out, hidden = model(batch, valid_elems)\n",
    "        print(\"\\nBatch:\", batch.grad_fn)\n",
    "        print(\"Out:\", out.grad_fn)\n",
    "        print(\"Hidden:\", hidden.grad_fn)\n",
    "        \n",
    "        out = rnn.pack_padded_sequence(out, valid_elems, enforce_sorted=False)\n",
    "        if i == 0 and print_stuff:\n",
    "            print(\"Output:\\t\", out.data.size())\n",
    "            print(\"Hidden:\\t\", hidden.data.size())\n",
    "\n",
    "\n",
    "        #print(out.data.size())\n",
    "        #print(labels.data.size())\n",
    "        loss = loss_function(out.data, labels.data)\n",
    "        print(loss, \"\\n\")\n",
    "    \n",
    "        '''\n",
    "        # This bit is replaced by packing labels and the line above\n",
    "        # Backpropping only through the non-padded parts\n",
    "        loss = 0\n",
    "        for j in range(out.size()[1]):\n",
    "        #print(out.size())\n",
    "        #print(torch.narrow(out, 1, j, 1).squeeze(1).size())\n",
    "        \n",
    "        narrowed_out = torch.narrow(torch.narrow(out, 1, j, 1).squeeze(1), 0, 0, valid_elems[j])\n",
    "        narrowed_labels = torch.narrow(labels[j], 0, 0, valid_elems[j])\n",
    "\n",
    "        #print_seq(narrowed_out[0].view(1,2000,23))\n",
    "        \n",
    "        print(narrowed_out.size())\n",
    "        print(narrowed_labels.size())\n",
    "        loss += loss_function(narrowed_out, narrowed_labels)\n",
    "        '''\n",
    "        #loss /= out.size()[1]\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        if loss.item() < min_loss:\n",
    "            torch.save(model.state_dict(), \"temp_best_model.pth\")\n",
    "            min_loss = loss.item()\n",
    "            no_improv = 0\n",
    "        else:\n",
    "            no_improv += 1\n",
    "        \n",
    "    \n",
    "    \n",
    "        # For tracking progress\n",
    "        end_time = datetime.now()\n",
    "        time_diff = end_time - start_time\n",
    "    \n",
    "        # Breaking when it's run through the given number of batches\n",
    "        if i+1 >= batches:\n",
    "            break\n",
    "\n",
    "torch.save(model.state_dict(), \"temp_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the loss through the epochs\n",
    "plt.plot(loss_list)\n",
    "#plt.scatter(range(len(loss_list)), loss_list)\n",
    "plt.title(\"Loss plotted through each batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Batch number\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.savefig(\"loss_log.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predicting\n",
    "accuracies = []\n",
    "load_model = True\n",
    "with torch.no_grad():\n",
    "    # Loading saved model from file\n",
    "    if load_model:\n",
    "        model.load_state_dict(torch.load(\"best_lstm.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    # Initalising data generator\n",
    "    #dataset = Dataset(small_file, max_seq_len, acids=acids)\n",
    "    #base_generator = data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    # For loops is easiest way to get an element from\n",
    "    # the generator even though we only loop once\n",
    "    for i, (batch, labels, valid_elems) in enumerate(base_generator):\n",
    "        test = batch\n",
    "        batch = batch.to(processor)\n",
    "        labels = labels.to(processor)\n",
    "\n",
    "        # Transposing from (batch x seq x feature_size) to (seq x batch x feature_size)\n",
    "        batch = batch.transpose(0,1)\n",
    "        #labels = torch.transpose(labels, 0, 1)\n",
    "\n",
    "        #batch = rnn.pack_padded_sequence(batch, valid_elems, enforce_sorted=False)\n",
    "\n",
    "        out, hidden = model(batch, valid_elems)\n",
    "\n",
    "        out = out.transpose(0,1)\n",
    "\n",
    "        print(out.size())\n",
    "        print(valid_elems.size())\n",
    "        for j in range(batch_size):\n",
    "            preds = torch.argmax(out[j], dim=1)[:valid_elems[j]]\n",
    "            actual = labels[j][:valid_elems[j]]\n",
    "            truths = [1 if pred == truth else 0 for pred, truth in zip(preds, actual)]\n",
    "            correct += sum(truths)\n",
    "        accuracy = correct/(torch.sum(valid_elems).item())\n",
    "        break\n",
    "\n",
    "print(labels.size())\n",
    "print(\"Test Accuracy: {0:.3f}%\".format(accuracy*100))\n",
    "\n",
    "#print(torch.argmax(out[0], dim=1))\n",
    "#print(torch.max(out[0,:10], dim=1))\n",
    "#print(torch.argmax(out[0,:10], dim=1))\n",
    "#print(out[0,:10])\n",
    "\n",
    "print(\"\\nPredictions\")\n",
    "print_seq(out[0].view(1,out.size()[1], out.size()[2]), valid_elems, acids)\n",
    "#print_seq(out, valid_elems, acids)\n",
    "print(\"\\nInput\")\n",
    "#print(test.size())\n",
    "print_test = \"\"\n",
    "for elem in test[0][:valid_elems[0]]:\n",
    "    print_test += acids[elem]\n",
    "print(print_test)\n",
    "#print_seq(test[0].view(1,test.size()[1], test.size()[2]), valid_elems, acids)\n",
    "\n",
    "print_labels = \"\"\n",
    "for elem in labels[0][:valid_elems[0]]:\n",
    "    print_labels += acids[elem]\n",
    "\n",
    "print(\"\\nLabels\")\n",
    "print(print_labels)\n",
    "\n",
    "#print_seq(out, valid_elems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## T-SNE and Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scope_file = \"scope_data_40.fasta\"\n",
    "scope_dataset = Dataset(scope_file, max_seq_len, output_type=\"embed\", acids=acids, get_prot_class=True)\n",
    "scope_generator = data.DataLoader(scope_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "load_model = True\n",
    "\n",
    "model_file = \"best_lstm.pth\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Loading saved model from file\n",
    "    if load_model:\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "\n",
    "    full_hidden = None\n",
    "    full_labels = []\n",
    "\n",
    "    for i, (batch, labels, valid_elems, prot_label) in enumerate(scope_generator):\n",
    "        batch = batch.to(processor)\n",
    "        labels = labels.to(processor)\n",
    "\n",
    "        # Transposing from (batch x seq x feature_size) to (seq x batch x feature_size)\n",
    "        batch = batch.transpose(0,1)\n",
    "        #labels = torch.transpose(labels, 0, 1)\n",
    "\n",
    "        #batch = rnn.pack_padded_sequence(batch, valid_elems, enforce_sorted=False)\n",
    "\n",
    "        out, hidden = model(batch, valid_elems)\n",
    "        \n",
    "        reduced_hidden = torch.mean(hidden, dim=0)\n",
    "\n",
    "        #print(list(prot_label))\n",
    "        full_labels = full_labels + list(prot_label)\n",
    "        if full_hidden is not None:\n",
    "            full_hidden = torch.cat((full_hidden, reduced_hidden), 0)\n",
    "        else:\n",
    "            full_hidden = reduced_hidden\n",
    "\n",
    "        if i >= 63:#float(\"inf\"):\n",
    "            break\n",
    "\n",
    "print(\"\\nFull Size:\", full_hidden.size())\n",
    "print(\"Starting TSNE\")\n",
    "t_sne = TSNE(n_components=2, perplexity=15, learning_rate=200).fit_transform(full_hidden.cpu())\n",
    "\n",
    "\n",
    "#print(full_labels)\n",
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "for unique in np.unique(full_labels):\n",
    "    mask = [elem==unique and unique != 'd' for elem in full_labels]\n",
    "    unique_list = t_sne[mask]\n",
    "    ax.scatter(unique_list[:,0], unique_list[:,1], label=unique, marker='.')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "fig.savefig(\"tsne_base_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": null,
   "machine_shape": "hm",
   "name": "Copy of protein_stuff.ipynb",
   "provenance": null
  },
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "protein_stuff.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
