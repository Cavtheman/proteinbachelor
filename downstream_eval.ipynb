{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils import data\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Our code\n",
    "from data_generator import Dataset\n",
    "from lstm import LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"stab_data/stability_train.json\"\n",
    "valid_file = \"stab_data/stability_valid.json\"\n",
    "test_file = \"stab_data/stability_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e7646e357b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mloaded_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_lstm.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmax_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'encoding'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    116\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "class stab_dataset(Dataset):\n",
    "    def __init__(self, filename, max_seq_len, output_type=\"onehot\", acids=\"ACDEFGHIKLMNPQRSTVWY-\"):\n",
    "        elem_list = []\n",
    "        label_list = []\n",
    "        self.acids = acids\n",
    "        self.output_type = output_type\n",
    "        self.acid_dict, self.int_acid_dict = self.__gen_acid_dict__(acids)\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.get_prot_class=True\n",
    "        # Loading the entire input file into memory\n",
    "        for i, elem in enumerate(json.load(open(filename))):\n",
    "            seq = elem[\"primary\"].upper()\n",
    "            if self.__is_legal_seq__(seq):\n",
    "                elem_list.append(seq)\n",
    "                label_list.append(elem[\"stability_score\"][0])\n",
    "        '''\n",
    "        for i, elem in enumerate(SeqIO.parse(filename, \"fasta\")):\n",
    "            if self.__is_legal_seq__(elem.seq.upper()):\n",
    "                elem_list.append(elem.seq.upper())\n",
    "                if get_prot_class:\n",
    "                    label_list.append(prot_class_re.search(elem.description).group(1))\n",
    "        '''\n",
    "        \n",
    "        self.data = elem_list\n",
    "        self.prot_labels = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class lin_reg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(lin_reg, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.long()\n",
    "        return self.linear(x)\n",
    "\n",
    "# Use Cuda if available\n",
    "use_cuda = torch.cuda.is_available() and True\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "processor = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "loaded_params = torch.load(\"best_lstm.pth\")\n",
    "\n",
    "max_seq_len = 500\n",
    "batch_size = 64\n",
    "hidden_dim = 512\n",
    "embed_size = 30\n",
    "hidden_layers = 1\n",
    "\n",
    "scope_file = \"scope_data_40.fasta\"\n",
    "acids = \"ACDEFGHIKLMNOPQRSTUVWY-\"\n",
    "\n",
    "stab_train = stab_dataset(train_file, 500, output_type=\"embed\", acids=acids)\n",
    "stab_valid = stab_dataset(valid_file, 500, output_type=\"embed\", acids=acids)\n",
    "stab_test = stab_dataset(test_file, 500, output_type=\"embed\", acids=acids)\n",
    "\n",
    "train_generator = data.DataLoader(stab_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "valid_generator = data.DataLoader(stab_valid, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_generator = data.DataLoader(stab_test, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "#model = LSTM_model(len(acids), embed_size, hidden_dim, hidden_layers, max_seq_len, batch_size, processor, dropout=0).to(processor)\n",
    "model = LSTM_model(**loaded_params[\"args_dict\"]).to(processor)\n",
    "model.load_state_dict(loaded_params[\"state_dict\"])\n",
    "\n",
    "top_model = lin_reg(hidden_dim, 1).to(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = float(\"inf\")\n",
    "time_diff = 0\n",
    "no_improv = 0\n",
    "min_loss = float(\"inf\")\n",
    "val_loss = float(\"inf\")\n",
    "epochs = 20\n",
    "loss_function = nn.MSELoss() \n",
    "optimiser = torch.optim.SGD(top_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (batch, labels, valid_elems, scores) in enumerate(train_generator):\n",
    "\n",
    "        # Keeping track of stuff\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        est_time_left = str(time_diff*(min(batches, stab_train.__len__()/batch_size) - i) + (time_diff*min(batches, stab_train.__len__()/batch_size)) * (epochs - (epoch+1))).split(\".\")[0]\n",
    "        sys.stdout.write(\"\\rEpoch: {0}. Batch: {1}. Train: {2:.5f}. Valid: {5:.5f} Estimated time left: {3}. Best: {4} batches ago.\".format(epoch+1, i+1, min_loss, est_time_left, no_improv, val_loss))\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        #model.eval()\n",
    "        top_model.train()\n",
    "        scores.requires_grad_(True)\n",
    "        batch = batch.to(processor)\n",
    "        labels = labels.to(processor)\n",
    "        scores = scores.to(processor)\n",
    "        \n",
    "        \n",
    "        # Transposing from (batch x seq x feature_size) to (seq x batch x feature_size)\n",
    "        batch = batch.transpose(0,1)\n",
    "        \n",
    "        out, hidden = model(batch, valid_elems)\n",
    "        \n",
    "        reduced_hidden = torch.mean(hidden, dim=0)\n",
    "        \n",
    "        #pred = top_model(test).squeeze(1)\n",
    "        pred = top_model(reduced_hidden).squeeze(1)\n",
    "\n",
    "        #print(pred[:64])\n",
    "\n",
    "        loss = loss_function(pred, scores)\n",
    "        #print(\"Loss:\", loss)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        if loss.item() < min_loss:\n",
    "            torch.save(top_model.state_dict(), \"temp_best_down_model.pth\")\n",
    "            min_loss = loss.item()\n",
    "            no_improv = 0\n",
    "        else:\n",
    "            no_improv += 1\n",
    "        \n",
    "        if i%50 == 0:\n",
    "            with torch.no_grad():\n",
    "                top_model.eval()\n",
    "                val_loss = 0\n",
    "                for j, (batch, labels, valid_elems, scores) in enumerate(valid_generator):\n",
    "                    scores.requires_grad_(True)\n",
    "                    batch = batch.to(processor)\n",
    "                    labels = labels.to(processor)\n",
    "                    scores = scores.to(processor)\n",
    "                    batch = batch.transpose(0,1)\n",
    "        \n",
    "                    out, hidden = model(batch, valid_elems)\n",
    "        \n",
    "                    reduced_hidden = torch.mean(hidden, dim=0)\n",
    "        \n",
    "                    pred = top_model(reduced_hidden).squeeze(1)\n",
    "\n",
    "                    val_loss += loss_function(pred, scores).item()\n",
    "\n",
    "                    if j+1 >= 5:\n",
    "                        break\n",
    "                val_loss /= j + 1\n",
    "\n",
    "        # For tracking progress\n",
    "        end_time = datetime.now()\n",
    "        time_diff = end_time - start_time\n",
    "        \n",
    "        # Breaking when it's run through the given number of batches\n",
    "        if i+1 >= batches:\n",
    "            \n",
    "            break\n",
    "    torch.save(top_model.state_dict(), \"temp_down_model.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds = None\n",
    "load_top = False\n",
    "if load_top:\n",
    "    top_model.load_state_dict(torch.load(\"temp_down_model.pth\"))\n",
    "\n",
    "    \n",
    "for i, (batch, labels, valid_elems, scores) in enumerate(test_generator):\n",
    "    scores.requires_grad_(True)\n",
    "    batch = batch.to(processor)\n",
    "    labels = labels.to(processor)\n",
    "    scores = scores.to(processor)\n",
    "    batch = batch.transpose(0,1)\n",
    "    \n",
    "    out, hidden = model(batch, valid_elems)\n",
    "\n",
    "    reduced_hidden = torch.mean(hidden, dim=0)\n",
    "    \n",
    "    preds = top_model(reduced_hidden).squeeze(1)\n",
    "\n",
    "    if full_preds is None:\n",
    "        full_preds = preds.detach()\n",
    "        full_scores = scores.detach()\n",
    "    else:\n",
    "        full_preds = torch.cat((full_preds, preds.detach()))\n",
    "        full_scores = torch.cat((full_scores, scores.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_preds.size())\n",
    "print(full_scores.size())\n",
    "print(full_preds[:64])\n",
    "print(full_scores[:64])\n",
    "spearman_vals = spearmanr(full_preds.cpu(), full_scores.cpu())\n",
    "print(spearman_vals)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,8))\n",
    "ax.scatter(full_preds.cpu(), full_scores.cpu(), s=2)\n",
    "line = np.linspace(-0.5,2, 10)\n",
    "ax.plot(line, line, color=\"red\")\n",
    "ax.set_title(\"Spearman's Rho: {0:.3f}\".format(spearman_vals[0]))\n",
    "ax.set_xlabel(\"Stability score prediction\")\n",
    "ax.set_ylabel(\"True Stability score\")\n",
    "ax.axis(\"equal\")\n",
    "fig.savefig(\"spearman_correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "downstream_eval.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
