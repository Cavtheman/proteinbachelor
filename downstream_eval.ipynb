{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "# Our code\n",
    "from data_generator import Dataset\n",
    "from lstm import LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file = \"stab_data/stability_train.json\"\n",
    "valid_file = \"stab_data/stability_valid.json\"\n",
    "test_file = \"stab_data/stability_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class stab_dataset(Dataset):\n",
    "    def __init__(self, filename, max_seq_len, output_type=\"onehot\", acids=\"ACDEFGHIKLMNPQRSTVWY-\"):\n",
    "        elem_list = []\n",
    "        label_list = []\n",
    "        self.acids = acids\n",
    "        self.output_type = output_type\n",
    "        self.acid_dict, self.int_acid_dict = self.__gen_acid_dict__(acids)\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.get_prot_class=True\n",
    "        # Loading the entire input file into memory\n",
    "        for i, elem in enumerate(json.load(open(filename))):\n",
    "            seq = elem[\"primary\"].upper()\n",
    "            if self.__is_legal_seq__(seq):\n",
    "                elem_list.append(seq)\n",
    "                label_list.append(elem[\"stability_score\"])\n",
    "        '''\n",
    "        for i, elem in enumerate(SeqIO.parse(filename, \"fasta\")):\n",
    "            if self.__is_legal_seq__(elem.seq.upper()):\n",
    "                elem_list.append(elem.seq.upper())\n",
    "                if get_prot_class:\n",
    "                    label_list.append(prot_class_re.search(elem.description).group(1))\n",
    "        '''\n",
    "        \n",
    "        self.data = elem_list\n",
    "        self.prot_labels = label_list\n",
    "\n",
    "class lin_reg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(lin_reg, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.long()\n",
    "        out = self.linear(x).long()\n",
    "        return out\n",
    "\n",
    "# Use Cuda if available\n",
    "use_cuda = torch.cuda.is_available() and True\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "processor = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "max_seq_len = 500\n",
    "batch_size = 64\n",
    "hidden_dim = 512\n",
    "embed_size = 30\n",
    "hidden_layers = 1\n",
    "\n",
    "scope_file = \"scope_data_40.fasta\"\n",
    "acids = \"ACDEFGHIKLMNOPQRSTUVWY-\"\n",
    "\n",
    "stab_train = stab_dataset(train_file, 500, output_type=\"embed\", acids=acids)\n",
    "stab_valid = stab_dataset(valid_file, 500, output_type=\"embed\", acids=acids)\n",
    "stab_test = stab_dataset(test_file, 500, output_type=\"embed\", acids=acids)\n",
    "\n",
    "train_generator = data.DataLoader(stab_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "valid_generator = data.DataLoader(stab_valid, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_generator = data.DataLoader(stab_test, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "model = LSTM_model(len(acids), embed_size, hidden_dim, hidden_layers, max_seq_len, batch_size, processor, dropout=0).to(processor)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_lstm.pth\"))\n",
    "\n",
    "top_model = lin_reg(hidden_dim, 1).to(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for param in top_model.parameters():\n",
    "    param.requires_grad=True\n",
    "loss_function = nn.MSELoss() \n",
    "optimiser = torch.optim.SGD(top_model.parameters(), lr=0.001)\n",
    "    \n",
    "for i, (batch, labels, valid_elems, scores) in enumerate(train_generator):\n",
    "    #with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    batch = batch.to(processor)\n",
    "    labels = labels.to(processor)\n",
    "    scores = scores[0].to(processor)\n",
    "    \n",
    "    \n",
    "    # Transposing from (batch x seq x feature_size) to (seq x batch x feature_size)\n",
    "    batch = batch.transpose(0,1)\n",
    "\n",
    "    print(\"Batch:\", batch.grad_fn)\n",
    "    out, hidden = model(batch, valid_elems)\n",
    "    print(\"Out:\", out.grad_fn)\n",
    "    print(\"Hidden:\", hidden.grad_fn)\n",
    "    reduced_hidden = torch.mean(hidden, dim=0)\n",
    "    print(\"Mean:\", reduced_hidden.grad_fn)\n",
    "\n",
    "    top_model.zero_grad()\n",
    "    top_model.train()\n",
    "    pred = top_model(reduced_hidden)\n",
    "    loss = loss_function(pred, scores.view(-1,1)).detach()\n",
    "    print(\"Loss:\", loss)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "downstream_eval.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
